# =====================
# æ—¥è¯­å­¦ä¹ åŠ©æ‰‹ä¸»ç¨‹åº
# =====================
# æœ¬æ–‡ä»¶ä¸º Streamlit åº”ç”¨ä¸»å…¥å£ï¼Œæ”¯æŒéŸ³è§†é¢‘ä¸Šä¼ ã€Whisperè½¬å†™ã€GPTæ™ºèƒ½åˆ†å¥ã€ç¿»è¯‘ã€å‡åæ ‡æ³¨ã€å•å¥åˆ†æç­‰åŠŸèƒ½ã€‚
# æ¯ä¸ªä¸»è¦æ­¥éª¤ã€å˜é‡ã€å‡½æ•°å‡æ·»åŠ è¯¦ç»†ä¸­æ–‡æ³¨é‡Šï¼Œä¾¿äºç†è§£å’Œç»´æŠ¤ã€‚

import os
import tempfile
import base64
import subprocess
import sys
from moviepy.editor import VideoFileClip
import re
import difflib

from dotenv import load_dotenv
import streamlit as st
import openai

# åŠ è½½ .env æ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡ï¼ˆå¦‚ OPENAI_API_KEYï¼‰
load_dotenv()

# ========== Streamlit Session State åˆå§‹åŒ– ==========
# ç”¨äºè·¨é¡µé¢/å¤šæ¬¡äº¤äº’æ—¶ä¿å­˜å˜é‡
if 'api_key' not in st.session_state:
    st.session_state.api_key = None
if 'segments' not in st.session_state:
    st.session_state.segments = None
if 'selected_language' not in st.session_state:
    st.session_state.selected_language = "ä¸­æ–‡"
if 'tmp_path' not in st.session_state:
    st.session_state.tmp_path = None
if 'show_manual' not in st.session_state:
    st.session_state.show_manual = True

# ========== API Key æ£€æŸ¥ä¸è¾“å…¥ ==========
def check_api_key():
    """
    æ£€æŸ¥ç”¨æˆ·æ˜¯å¦å·²è¾“å…¥ OpenAI API Keyã€‚
    è‹¥æœªè¾“å…¥ï¼Œåˆ™åœ¨ä¾§è¾¹æ æç¤ºè¾“å…¥ï¼Œè¾“å…¥åå†™å…¥ session å¹¶åˆ·æ–°é¡µé¢ã€‚
    è¿”å›æ˜¯å¦å·²è®¾ç½® API key çš„çŠ¶æ€ã€‚
    """
    current_lang = LANGUAGE_MAPPINGS[st.session_state.selected_language]
    if st.session_state.api_key is None:
        st.warning(current_lang["api_key_warning"])
        api_key = st.text_input(current_lang["api_key_input"], type="password")
        if api_key:
            st.session_state.api_key = api_key
            openai.api_key = api_key
            st.success(current_lang["api_key_success"])
            st.rerun()
        return False
    return True

# ========== å¤šè¯­è¨€ç•Œé¢æ–‡æœ¬æ˜ å°„ ==========
LANGUAGE_MAPPINGS = {
    "ä¸­æ–‡": {
        "title": "ğŸŒ¸ æ—¥è¯­å­¦ä¹ åŠ©æ‰‹",
        "upload_text": "ä¸Šä¼ éŸ³/è§†é¢‘æ–‡ä»¶",
        "start_button": "â–¶ å¼€å§‹ç”Ÿæˆ",
        "transcribing": "æ­£åœ¨è°ƒç”¨ Whisper è¿›è¡Œè½¬å†™â€¦",
        "sentence_analysis": "å¥å­åˆ†æ",
        "current_sentence": "å½“å‰å¥å­ï¼š",
        "translation_system": "ä½ æ˜¯æ—¥æ–‡â†’ä¸­æ–‡ä¸“ä¸šç¿»è¯‘ï¼Œåªè¾“å‡ºä¸€å¥æµç•…çš„ä¸­æ–‡è¯‘æ–‡ã€‚",
        "reading_module": "ğŸ§ å•å¥æœ—è¯»æ¨¡å—",
        "analysis_module": "ğŸ“ å•å¥åˆ†ææ¨¡å—",
        "full_text": "å…¨æ–‡",
        "hover_tip": "ğŸ’¡ å°†é¼ æ ‡æ‚¬åœåœ¨å¥å­ä¸Šï¼Œç‚¹å‡»å³å¯è¿›è¡Œåˆ†æ",
        "loop_play": "å¾ªç¯æ’­æ”¾",
        "cancel_loop": "å–æ¶ˆå¾ªç¯",
        "click_to_analyze": "ç‚¹å‡»åˆ†ææ­¤å¥",
        "api_key_warning": "è¯·å…ˆè¾“å…¥æ‚¨çš„ OpenAI API Key",
        "api_key_input": "OpenAI API Key",
        "api_key_success": "API Key å·²è®¾ç½®ï¼",
        "manual": """
    ### ğŸ“– ä½¿ç”¨æ‰‹å†Œ

    #### ğŸ¯ ç³»ç»ŸåŠŸèƒ½
    æœ¬ç³»ç»Ÿæ”¯æŒä¸Šä¼ å«æœ‰æ—¥è¯­çš„éŸ³é¢‘æˆ–è§†é¢‘æ–‡ä»¶ï¼Œæä¾›ä»¥ä¸‹å­¦ä¹ åŠŸèƒ½ï¼š

    #### ğŸ§ å•å¥æœ—è¯»æ¨¡å—
    - æ”¯æŒä¸Šä¼  MP4ã€MOVã€MP3ã€WAV æ ¼å¼çš„éŸ³é¢‘/è§†é¢‘æ–‡ä»¶
    - è‡ªåŠ¨ç”Ÿæˆæ—¥è¯­å­—å¹•å’Œä¸­æ–‡ç¿»è¯‘
    - ç‚¹å‡»å­—å¹•å¯è·³è½¬åˆ°å¯¹åº”è§†é¢‘æ—¶é—´ç‚¹
    - æ”¯æŒå•å¥å¾ªç¯æ’­æ”¾åŠŸèƒ½ï¼Œæ–¹ä¾¿è·Ÿè¯»ç»ƒä¹ 
    - å½“å‰æ’­æ”¾å¥å­ä¼šè‡ªåŠ¨é«˜äº®æ˜¾ç¤º

    #### ğŸ“ å•å¥åˆ†ææ¨¡å—
    - æ˜¾ç¤ºå®Œæ•´çš„æ—¥è¯­åŸæ–‡å’Œä¸­æ–‡ç¿»è¯‘å¯¹ç…§
    - ç‚¹å‡»ä»»æ„å¥å­å¯è¿›è¡Œæ·±åº¦åˆ†æ
    - åˆ†æå†…å®¹åŒ…æ‹¬ï¼šé‡è¦è¯æ±‡ï¼ˆå‡åã€è¯æ€§ã€ä¸­æ–‡æ„æ€ï¼‰å’Œè¯­æ³•ç‚¹ï¼ˆè¯­æ³•ç»“æ„ã€ç”¨æ³•è¯´æ˜ã€ä¾‹å¥ï¼‰

    #### ğŸ’¡ ä½¿ç”¨æç¤º
    - ä¸Šä¼ æ–‡ä»¶åç‚¹å‡»"å¼€å§‹ç”Ÿæˆ"æŒ‰é’®
    - ç­‰å¾…ç³»ç»Ÿå¤„ç†å®Œæˆåå³å¯å¼€å§‹å­¦ä¹ 
    - å¯ä»¥éšæ—¶åˆ‡æ¢ç•Œé¢è¯­è¨€ï¼ˆä¸­æ–‡/è‹±æ–‡/éŸ©æ–‡ï¼‰
    - å»ºè®®å…ˆä½¿ç”¨å•å¥æœ—è¯»æ¨¡å—è¿›è¡Œè·Ÿè¯»ç»ƒä¹ ï¼Œå†ä½¿ç”¨å•å¥åˆ†ææ¨¡å—æ·±å…¥å­¦ä¹ 
    """
    },
    "English": {
        "title": "ğŸŒ¸ Japanese Learning Assistant",
        "upload_text": "Upload Audio/Video File",
        "start_button": "â–¶ Start Generation",
        "transcribing": "Transcribing with Whisper...",
        "sentence_analysis": "Sentence Analysis",
        "current_sentence": "Current Sentence: ",
        "translation_system": "You are a professional Japanese to English translator. Output only a fluent English translation.",
        "reading_module": "ğŸ§ Single Sentence Reading Module",
        "analysis_module": "ğŸ“ Single Sentence Analysis Module",
        "full_text": "Full Text",
        "hover_tip": "ğŸ’¡ Hover over a sentence and click to analyze",
        "loop_play": "Loop Play",
        "cancel_loop": "Cancel Loop",
        "click_to_analyze": "Click to analyze",
        "api_key_warning": "Please enter your OpenAI API Key first",
        "api_key_input": "OpenAI API Key",
        "api_key_success": "API Key has been set!",
        "manual": """
    ### ğŸ“– User Manual

    #### ğŸ¯ System Features
    This system supports uploading Japanese audio or video files and provides the following learning features:

    #### ğŸ§ Single Sentence Reading Module
    - Supports uploading MP4, MOV, MP3, WAV format audio/video files
    - Automatically generates Japanese subtitles and English translations
    - Click on subtitles to jump to corresponding video timestamps
    - Supports single sentence loop playback for practice
    - Currently playing sentence is automatically highlighted

    #### ğŸ“ Single Sentence Analysis Module
    - Displays complete Japanese text and English translation
    - Click any sentence for in-depth analysis
    - Analysis includes: important vocabulary (pronunciation, part of speech, meaning) and grammar points (structure, usage, examples)

    #### ğŸ’¡ Usage Tips
    - Click 'Start Generation' after uploading a file
    - Wait for system processing to complete before starting
    - Switch interface language anytime (Chinese/English/Korean)
    - Recommended: practice with reading module first, then use analysis module for deeper learning
    """
    },
    "í•œêµ­ì–´": {
        "title": "ğŸŒ¸ ì¼ë³¸ì–´ í•™ìŠµ ë„ìš°ë¯¸",
        "upload_text": "ì˜¤ë””ì˜¤/ë¹„ë””ì˜¤ íŒŒì¼ ì—…ë¡œë“œ",
        "start_button": "â–¶ ìƒì„± ì‹œì‘",
        "transcribing": "Whisperë¡œ ì „ì‚¬ ì¤‘...",
        "sentence_analysis": "ë¬¸ì¥ ë¶„ì„",
        "current_sentence": "í˜„ì¬ ë¬¸ì¥: ",
        "translation_system": "ë‹¹ì‹ ì€ ì¼ë³¸ì–´â†’í•œêµ­ì–´ ì „ë¬¸ ë²ˆì—­ê°€ì…ë‹ˆë‹¤. ìœ ì°½í•œ í•œêµ­ì–´ ë²ˆì—­ë§Œ ì¶œë ¥í•˜ì„¸ìš”.",
        "reading_module": "ğŸ§ ë‹¨ë¬¸ì¥ ì½ê¸° ëª¨ë“ˆ",
        "analysis_module": "ğŸ“ ë‹¨ë¬¸ì¥ ë¶„ì„ ëª¨ë“ˆ",
        "full_text": "ì „ì²´ í…ìŠ¤íŠ¸",
        "hover_tip": "ğŸ’¡ ë¬¸ì¥ì— ë§ˆìš°ìŠ¤ë¥¼ ì˜¬ë¦¬ê³  í´ë¦­í•˜ì—¬ ë¶„ì„",
        "loop_play": "ë°˜ë³µ ì¬ìƒ",
        "cancel_loop": "ë°˜ë³µ ì·¨ì†Œ",
        "click_to_analyze": "ë¶„ì„í•˜ë ¤ë©´ í´ë¦­",
        "api_key_warning": "OpenAI API Keyë¥¼ ë¨¼ì € ì…ë ¥í•´ì£¼ì„¸ìš”",
        "api_key_input": "OpenAI API Key",
        "api_key_success": "API Keyê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤!",
        "manual": """
    ### ğŸ“– ì‚¬ìš© ì„¤ëª…ì„œ

    #### ğŸ¯ ì‹œìŠ¤í…œ ê¸°ëŠ¥
    ì´ ì‹œìŠ¤í…œì€ ì¼ë³¸ì–´ ì˜¤ë””ì˜¤ ë˜ëŠ” ë¹„ë””ì˜¤ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ë‹¤ìŒ í•™ìŠµ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤:

    #### ğŸ§ ë‹¨ë¬¸ì¥ ì½ê¸° ëª¨ë“ˆ
    - MP4, MOV, MP3, WAV í˜•ì‹ì˜ ì˜¤ë””ì˜¤/ë¹„ë””ì˜¤ íŒŒì¼ ì—…ë¡œë“œ ì§€ì›
    - ì¼ë³¸ì–´ ìë§‰ê³¼ í•œêµ­ì–´ ë²ˆì—­ ìë™ ìƒì„±
    - ìë§‰ í´ë¦­ ì‹œ í•´ë‹¹ ë¹„ë””ì˜¤ ì‹œê°„ìœ¼ë¡œ ì´ë™
    - ì—°ìŠµì„ ìœ„í•œ ë‹¨ë¬¸ì¥ ë°˜ë³µ ì¬ìƒ ì§€ì›
    - í˜„ì¬ ì¬ìƒ ì¤‘ì¸ ë¬¸ì¥ ìë™ ê°•ì¡° í‘œì‹œ

    #### ğŸ“ ë‹¨ë¬¸ì¥ ë¶„ì„ ëª¨ë“ˆ
    - ì™„ì „í•œ ì¼ë³¸ì–´ í…ìŠ¤íŠ¸ì™€ í•œêµ­ì–´ ë²ˆì—­ í‘œì‹œ
    - ë¬¸ì¥ í´ë¦­ ì‹œ ì‹¬ì¸µ ë¶„ì„
    - ë¶„ì„ ë‚´ìš©: ì¤‘ìš” ì–´íœ˜(ë°œìŒ, í’ˆì‚¬, ì˜ë¯¸) ë° ë¬¸ë²• í¬ì¸íŠ¸(êµ¬ì¡°, ìš©ë²•, ì˜ˆë¬¸)

    #### ğŸ’¡ ì‚¬ìš© íŒ
    - íŒŒì¼ ì—…ë¡œë“œ í›„ 'ìƒì„± ì‹œì‘' í´ë¦­
    - ì‹œìŠ¤í…œ ì²˜ë¦¬ê°€ ì™„ë£Œë  ë•Œê¹Œì§€ ëŒ€ê¸°
    - ì–¸ì–´ ì „í™˜ ê°€ëŠ¥(ì¤‘êµ­ì–´/ì˜ì–´/í•œêµ­ì–´)
    - ê¶Œì¥: ì½ê¸° ëª¨ë“ˆë¡œ ë¨¼ì € ì—°ìŠµí•œ í›„ ë¶„ì„ ëª¨ë“ˆë¡œ ì‹¬í™” í•™ìŠµ
    """
    }
}

# ========== é¡µé¢é…ç½®ä¸è‡ªå®šä¹‰æ ·å¼ ==========
st.set_page_config(page_title="ğŸŒ¸ æ—¥è¯­å­¦ä¹ åŠ©æ‰‹", layout="wide")

# æ·»åŠ è‡ªå®šä¹‰ CSS æ ·å¼ï¼ˆç¾åŒ–æ ‡é¢˜ã€æ¨¡å—æ ‡é¢˜ç­‰ï¼‰
st.markdown("""
<style>
    /* æ ‡é¢˜æ ·å¼ */
    .japanese-title {
        font-family: "Hiragino Sans", "Hiragino Kaku Gothic ProN", "Meiryo", sans-serif;
        color: #333;
        text-align: center;
        padding: 20px;
        margin-bottom: 30px;
    }
    
    /* æ¨¡å—æ ‡é¢˜æ ·å¼ */
    .module-title {
        font-family: "Hiragino Sans", "Hiragino Kaku Gothic ProN", "Meiryo", sans-serif;
        color: #2c3e50;
        border-left: 4px solid #e74c3c;
        padding-left: 10px;
        margin: 20px 0;
    }
</style>
""", unsafe_allow_html=True)

# ========== ä¾§è¾¹æ è¯­è¨€é€‰æ‹©ä¸æ–‡ä»¶ä¸Šä¼  ==========
with st.sidebar:
    selected_language = st.selectbox(
        "é€‰æ‹©è¯­è¨€ / Select Language / ì–¸ì–´ ì„ íƒ",
        options=list(LANGUAGE_MAPPINGS.keys()),
        index=list(LANGUAGE_MAPPINGS.keys()).index(st.session_state.selected_language)
    )
    st.session_state.selected_language = selected_language
    current_lang = LANGUAGE_MAPPINGS[selected_language]
    
    # æ£€æŸ¥ API key
    has_api_key = check_api_key()
    
    # æ–‡ä»¶ä¸Šä¼ æ§ä»¶ï¼Œæ”¯æŒå¤šç§éŸ³è§†é¢‘æ ¼å¼
    uploaded = st.file_uploader(current_lang["upload_text"], type=['mp4', 'mp3', 'wav', 'mov'], disabled=not has_api_key)
    if uploaded and has_api_key:
        # ä¿å­˜ä¸Šä¼ çš„ä¸´æ—¶æ–‡ä»¶
        suffix = os.path.splitext(uploaded.name)[1]
        with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
            tmp.write(uploaded.read())
            st.session_state.tmp_path = tmp.name
        # ç”ŸæˆæŒ‰é’®ï¼Œç‚¹å‡»åå¼€å§‹è½¬å†™
        if st.button(current_lang["start_button"]):
            with st.spinner(current_lang["transcribing"]):
                input_file = st.session_state.tmp_path
                # è‹¥ä¸ºè§†é¢‘ï¼Œå…ˆæå–éŸ³é¢‘
                if input_file.lower().endswith(('.mp4', '.mov')):
                    try:
                        video = VideoFileClip(input_file)
                        with tempfile.NamedTemporaryFile(suffix='.mp3', delete=False) as temp_audio:
                            temp_audio_path = temp_audio.name
                        video.audio.write_audiofile(temp_audio_path, codec='libmp3lame', fps=44100, nbytes=4, bitrate='192k')
                        video.close()
                        input_file = temp_audio_path
                    except Exception as e:
                        st.error(f"å¤„ç†æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
                        st.stop()
                # Whisper è¯­éŸ³è½¬å†™
                try:
                    resp = openai.Audio.transcribe(
                        file=open(input_file, "rb"),
                        model="whisper-1",
                        response_format="verbose_json"
                    )
                    st.session_state.segments = resp.get("segments", [])
                    st.session_state.show_manual = False
                    st.rerun()
                except Exception as e:
                    st.error(f"è½¬å†™è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
                finally:
                    if input_file != st.session_state.tmp_path:
                        try:
                            os.unlink(input_file)
                        except:
                            pass

# ========== ä¸»é¡µé¢å†…å®¹æ¸²æŸ“ ==========
# æ˜¾ç¤ºæ‰‹å†Œ
st.markdown(f"""
<h1 class="japanese-title">{current_lang['title']}</h1>
""", unsafe_allow_html=True)
if st.session_state.show_manual:
    st.markdown(current_lang['manual'])

# ========== æ—¶é—´æˆ³æ ¼å¼åŒ–å·¥å…· ==========
def fmt(ts: float) -> str:
    """å°†ç§’æ•°æ ¼å¼åŒ–ä¸º 00:00:00.000 å­—ç¬¦ä¸²"""
    h = int(ts // 3600)
    m = int((ts % 3600) // 60)
    s = int(ts % 60)
    ms = int((ts - int(ts)) * 1000)
    return f"{h:02d}:{m:02d}:{s:02d}.{ms:03d}"

# ========== Whisperè½¬å†™åä¸»æµç¨‹ ==========
if st.session_state.segments:
    # å•å¥æœ—è¯»æ¨¡å—æ ‡é¢˜
    st.markdown(f'<h2 class="module-title">{current_lang["reading_module"]}</h2>', unsafe_allow_html=True)
    # å– Whisper åŸå§‹åˆ†å¥æ–‡æœ¬
    raw_sentences = [seg["text"].strip() for seg in st.session_state.segments]
    # æ„é€ å¤§æ¨¡å‹åˆå¹¶åˆ†å¥çš„æç¤ºè¯
    merge_prompt = (
        "æ˜¯è‡ªåŠ¨è¯­éŸ³è¯†åˆ«åˆ†å‰²çš„æ—¥è¯­å¥å­åˆ—è¡¨ï¼Œéƒ¨åˆ†å¥å­è¢«é”™è¯¯æ‹†åˆ†ã€‚"
        "è¯·ä½ æ ¹æ®è¯­ä¹‰å’Œè¯­æ³•ï¼Œå°†åº”è¯¥åˆå¹¶çš„å¥å­åˆå¹¶ï¼Œè¾“å‡ºåˆå¹¶åçš„å®Œæ•´æ—¥è¯­å¥å­åˆ—è¡¨ï¼ˆæ¯å¥ä¸€è¡Œï¼‰ï¼š\n"
        + "\n".join(f"{i+1}. {s}" for i, s in enumerate(raw_sentences))
    )
    try:
        # è°ƒç”¨å¤§æ¨¡å‹æ™ºèƒ½åˆå¹¶åˆ†å¥
        merge_response = openai.ChatCompletion.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯æ—¥è¯­æ¯è¯­è€…ï¼Œæ“…é•¿æ ¹æ®è¯­ä¹‰å’Œè¯­æ³•åˆ¤æ–­å¥å­è¾¹ç•Œã€‚"},
                {"role": "user", "content": merge_prompt}
            ]
        )
        # å»é™¤ç¼–å·ï¼Œåªä¿ç•™å†…å®¹
        merged_sentences = [re.sub(r'^[0-9]+[.ã€]\s*', '', line.strip()) for line in merge_response.choices[0].message.content.splitlines() if line.strip()]
        # ç”¨ Whisper çš„ç¬¬ä¸€å¥å’Œå¤§æ¨¡å‹ç¬¬ä¸€å¥åšç›¸ä¼¼åº¦åˆ¤æ–­ï¼Œé˜²æ­¢å¤§æ¨¡å‹è¾“å‡ºæç¤ºè¯­
        first_raw = raw_sentences[0]
        if merged_sentences:
            first_merged = merged_sentences[0]
            similarity = difflib.SequenceMatcher(None, first_raw, first_merged).ratio()
            if similarity < 0.2:
                merged_sentences = merged_sentences[1:]
    except Exception as e:
        st.error(f"æ™ºèƒ½åˆå¹¶åˆ†å¥æ—¶å‡ºé”™: {str(e)}ï¼Œå°†ä½¿ç”¨åŸå§‹åˆ†å¥ã€‚")
        merged_sentences = raw_sentences

    # ç”Ÿæˆ WebVTT å­—å¹•å’Œå…¨æ–‡åˆ†ææ•°æ®
    vtt = "WEBVTT\n\n"
    transcript_data = []
    for i, ja in enumerate(merged_sentences, start=1):
        # è®¡ç®—æ¯å¥çš„èµ·æ­¢æ—¶é—´æˆ³
        start_ts = fmt(st.session_state.segments[0]["start"]) if i == 1 else fmt(st.session_state.segments[i-1]["end"])
        end_ts = fmt(st.session_state.segments[i]["end"]) if i < len(st.session_state.segments) else fmt(st.session_state.segments[-1]["end"])
        # ç¿»è¯‘æ—¥æ–‡åˆ°ä¸­æ–‡
        chat = openai.ChatCompletion.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": f"{current_lang['translation_system']} æ³¨æ„ï¼šè¿™æ˜¯ä¸€ä¸ªæ—¥è¯­å­¦ä¹ ç³»ç»Ÿï¼Œè¯·ç¡®ä¿ç¿»è¯‘çš„å‡†ç¡®æ€§å’Œæµç•…æ€§ã€‚å¦‚æœé‡åˆ°ä¸å®Œæ•´çš„å¥å­ç‰‡æ®µï¼Œè¯·æ ¹æ®ä¸Šä¸‹æ–‡ç†è§£å®Œæ•´æ„æ€åå†ç¿»è¯‘ã€‚ç¿»è¯‘æ—¶è¦æ³¨æ„ä¿æŒæ—¥è¯­çš„è¯­è¨€ç‰¹ç‚¹å’Œè¡¨è¾¾æ–¹å¼ã€‚"},
                {"role": "user", "content": ja}
            ]
        )
        zh = chat.choices[0].message.content.strip()
        # è·å–å¸¦å‡åçš„æ—¥æ–‡
        furigana_chat = openai.ChatCompletion.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæ—¥è¯­ä¸“å®¶ã€‚è¯·å°†ä»¥ä¸‹æ—¥è¯­å¥å­è½¬æ¢ä¸ºå¸¦å‡åçš„æ ¼å¼ï¼Œä½¿ç”¨HTMLçš„rubyæ ‡ç­¾ã€‚åªå¯¹æ±‰å­—æ·»åŠ å‡åè¯»éŸ³ï¼Œå‡åéƒ¨åˆ†ä¿æŒåŸæ ·ã€‚å¦‚æœé‡åˆ°ä¸å®Œæ•´çš„å¥å­ç‰‡æ®µï¼Œè¯·æ ¹æ®ä¸Šä¸‹æ–‡ç†è§£å®Œæ•´æ„æ€åå†æ·»åŠ å‡åã€‚ç¡®ä¿å‡åæ ‡æ³¨çš„å‡†ç¡®æ€§å’Œå®Œæ•´æ€§ã€‚ä¾‹å¦‚ï¼š<ruby>æ—¥æœ¬èª<rt>ã«ã»ã‚“ã”</rt></ruby>ã‚’<ruby>å‹‰å¼·<rt>ã¹ã‚“ãã‚‡ã†</rt></ruby>ã™ã‚‹ã€‚åªè¾“å‡ºè½¬æ¢åçš„æ–‡æœ¬ã€‚"},
                {"role": "user", "content": ja}
            ]
        )
        ja_with_furigana = furigana_chat.choices[0].message.content.strip()
        # å­˜å‚¨æ¯å¥çš„åˆ†ææ•°æ®
        transcript_data.append({
            "index": i,
            "start": start_ts,
            "end": end_ts,
            "ja": ja,
            "zh": zh,
            "ja_with_furigana": ja_with_furigana
        })
        # æ‹¼æ¥ VTT å­—å¹•å†…å®¹
        vtt += f"{i}\n{start_ts} --> {end_ts}\n{ja}\n{zh}\n\n"

    # Base64 ç¼–ç è§†é¢‘å’Œ VTT
    with open(st.session_state.tmp_path, 'rb') as f:
        video_b64 = base64.b64encode(f.read()).decode()
    subtitle_b64 = base64.b64encode(vtt.encode()).decode()

    # æ„å»ºå…¨æ–‡ç¿»è¯‘ HTML
    transcript_html = ""
    for item in transcript_data:
        transcript_html += f"""
        <div class="transcript-line" id="line-{item['index']}" onclick="handleSentenceClick({item['index']}, '{item['start']}', '{item['ja']}')" data-start="{item['start']}" data-end="{item['end']}">
          <div class="ja">{item['ja_with_furigana']}</div>
          <div class="zh">{item['zh']}</div>
          <div class="button-group">
            <button class="loop-button" onclick="handleLoopPlay({item['index']}, '{item['start']}', '{item['end']}')">{current_lang['loop_play']}</button>
            <button class="cancel-loop-button" onclick="handleCancelLoop({item['index']})" style="display: none;">{current_lang['cancel_loop']}</button>
          </div>
        </div>
        """

    # ç»¼åˆ HTML: å·¦ä¾§è§†é¢‘ï¼Œä¸æ˜¾ç¤ºè‡ªå¸¦å­—å¹•ï¼›å³ä¾§å…¨æ–‡å¹¶çº¢è‰²é«˜äº®å½“å‰å¥å¼
    html = f"""
    <style>
      .container {{ display: flex; }}
      .video-section {{ flex: 2; padding-right: 16px; }}
      .transcript-section {{ flex: 1; max-height: 600px; overflow-y: auto; border-left: 1px solid #ddd; padding-left: 16px; }}
      .video-container {{ position: relative; width: 100%; padding-top: 56.25%; }}
      .video-container video {{ position: absolute; top:0; left:0; width:100%; height:100%; object-fit:contain; }}

      /* éšè— video è‡ªå¸¦å­—å¹•æ¸²æŸ“ */
      video::cue {{ display: none; }}

      .transcript-line {{ 
        padding: 8px; 
        transition: background 0.3s; 
        cursor: pointer;
        border-radius: 4px;
        position: relative;
        margin-bottom: 12px;
        border-bottom: 1px solid #eee;
      }}
      .transcript-line:hover {{ 
        background: #f0f0f0; 
      }}
      .transcript-line.highlight {{ 
        background: #ffcccc; 
      }}
      .ja {{ 
        margin-left: 8px; 
        color: #1a73e8; 
        font-size: 1.2em; 
        font-weight: 500;
        margin-bottom: 4px;
        line-height: 2;
      }}
      .ja ruby {{
        ruby-position: over;
        ruby-align: center;
      }}
      .ja rt {{
        font-size: 0.65em;
        color: #666;
        font-weight: normal;
        padding: 0 1px;
      }}
      .zh {{ 
        margin-left: 8px; 
        color: #333; 
        font-size: 1.1em;
        padding-left: 12px;
        border-left: 3px solid #1a73e8;
        line-height: 1.4;
      }}

      .button-group {{
        position: absolute;
        right: 10px;
        top: 50%;
        transform: translateY(-50%);
        display: flex;
        gap: 8px;
        opacity: 0;
        transition: opacity 0.3s ease;
      }}

      .transcript-line:hover .button-group {{
        opacity: 1;
      }}

      .loop-button, .cancel-loop-button {{
        background: #4CAF50;
        color: white;
        border: none;
        padding: 5px 10px;
        border-radius: 4px;
        cursor: pointer;
        font-size: 0.9em;
        min-width: 80px;
      }}

      .cancel-loop-button {{
        background: #f44336;
        display: none;
      }}

      .loop-button:hover {{
        background: #45a049;
      }}

      .cancel-loop-button:hover {{
        background: #d32f2f;
      }}

      .transcript-line.looping .loop-button {{
        display: none;
      }}

      .transcript-line.looping .cancel-loop-button {{
        display: block !important;
      }}

      .transcript-line.looping .button-group {{
        opacity: 1 !important;
      }}
    </style>
    <div class="container">
      <div class="video-section">
        <div class="video-container">
          <video id="vid" controls crossorigin>
            <source src="data:video/mp4;base64,{video_b64}" type="video/mp4">
            <track kind="subtitles" srclang="ja" label="æ—¥/ä¸­" src="data:text/vtt;base64,{subtitle_b64}" default>
          </video>
        </div>
      </div>
      <div class="transcript-section" id="full-transcript">
        {transcript_html}
      </div>
    </div>
    <script>
      const video = document.getElementById('vid');
      const transcriptSection = document.getElementById('full-transcript');
      let currentHighlightedIndex = null;
      let isManualHighlight = false;
      let loopInterval = null;
      let currentLoopingIndex = null;

      function clearHighlights() {{
        const lines = transcriptSection.getElementsByClassName('transcript-line');
        for (let line of lines) {{ 
          line.classList.remove('highlight');
          line.classList.remove('looping');
        }}
      }}

      function parseTimestamp(timestamp) {{
        const [time, ms] = timestamp.split('.');
        const [hours, minutes, seconds] = time.split(':');
        return parseFloat(hours) * 3600 + parseFloat(minutes) * 60 + parseFloat(seconds) + parseFloat('0.' + ms);
      }}

      function highlightSentence(index) {{
        clearHighlights();
        const el = document.getElementById('line-' + index);
        if (el) {{
          el.classList.add('highlight');
          el.scrollIntoView({{ behavior: 'smooth', block: 'nearest' }});
          currentHighlightedIndex = index;
        }}
      }}

      function handleSentenceClick(index, timestamp, sentence) {{
        // å‘é€æ¶ˆæ¯åˆ° Streamlit
        window.parent.postMessage({{
          type: 'sentence_click',
          data: {{
            index: index,
            timestamp: timestamp,
            sentence: sentence
          }}
        }}, '*');

        // è·³è½¬åˆ°è§†é¢‘æ—¶é—´ç‚¹
        const totalSeconds = parseTimestamp(timestamp);
        video.currentTime = totalSeconds;
        
        // é«˜äº®æ˜¾ç¤ºå½“å‰å¥å­
        highlightSentence(index);
        isManualHighlight = true;

        // è®¾ç½®ä¸€ä¸ªå®šæ—¶å™¨ï¼Œåœ¨è§†é¢‘å¼€å§‹æ’­æ”¾åé‡ç½®æ‰‹åŠ¨é«˜äº®çŠ¶æ€
        setTimeout(() => {{
          isManualHighlight = false;
        }}, 1000);
      }}

      function handleLoopPlay(index, startTime, endTime) {{
        // é˜»æ­¢äº‹ä»¶å†’æ³¡ï¼Œé˜²æ­¢è§¦å‘å¥å­çš„ç‚¹å‡»äº‹ä»¶
        event.stopPropagation();
        
        // æ¸…é™¤ä¹‹å‰çš„å¾ªç¯
        if (loopInterval) {{
          clearInterval(loopInterval);
        }}
        
        // è®¾ç½®è§†é¢‘çš„å½“å‰æ—¶é—´åˆ°å¥å­å¼€å§‹æ—¶é—´
        const startSeconds = parseTimestamp(startTime);
        const endSeconds = parseTimestamp(endTime);
        video.currentTime = startSeconds;
        
        // æ’­æ”¾è§†é¢‘
        video.play();
        
        // è®¾ç½®å¾ªç¯æ’­æ”¾
        loopInterval = setInterval(() => {{
          if (video.currentTime >= endSeconds) {{
            video.currentTime = startSeconds;
          }}
        }}, 100);

        // æ›´æ–°UIçŠ¶æ€
        clearHighlights();
        const el = document.getElementById('line-' + index);
        if (el) {{
          el.classList.add('highlight');
          el.classList.add('looping');
          currentLoopingIndex = index;
        }}
      }}

      function handleCancelLoop(index) {{
        // é˜»æ­¢äº‹ä»¶å†’æ³¡
        event.stopPropagation();
        
        // æ¸…é™¤å¾ªç¯æ’­æ”¾
        if (loopInterval) {{
          clearInterval(loopInterval);
          loopInterval = null;
        }}
        
        // æ›´æ–°UIçŠ¶æ€
        const el = document.getElementById('line-' + index);
        if (el) {{
          el.classList.remove('looping');
        }}
        currentLoopingIndex = null;
        
        // ç»§ç»­æ’­æ”¾è§†é¢‘
        video.play();
      }}

      video.addEventListener('loadedmetadata', () => {{
        const track = video.textTracks[0];
        track.mode = 'hidden';  // éšè—æ¸²æŸ“ä½†ä¿ç•™ cue äº‹ä»¶

        track.addEventListener('cuechange', () => {{
          const activeCues = track.activeCues;
          if (activeCues.length > 0) {{
            const cue = activeCues[0];
            const cues = track.cues;
            for (let i = 0; i < cues.length; i++) {{
              if (cues[i] === cue) {{
                const idx = i + 1;
                // åªæœ‰åœ¨æ²¡æœ‰æ‰‹åŠ¨é«˜äº®ä¸”æ²¡æœ‰å¾ªç¯æ’­æ”¾æ—¶æ‰è‡ªåŠ¨æ›´æ–°é«˜äº®
                if (!isManualHighlight && !currentLoopingIndex) {{
                  highlightSentence(idx);
                }}
                break;
              }}
            }}
          }}
        }});

        // æ·»åŠ è§†é¢‘æ’­æ”¾äº‹ä»¶ç›‘å¬
        video.addEventListener('play', () => {{
          // å¼€å§‹æ’­æ”¾æ—¶é‡ç½®æ‰‹åŠ¨é«˜äº®çŠ¶æ€
          isManualHighlight = false;
        }});

        video.addEventListener('pause', () => {{
          // æš‚åœæ—¶æ¸…é™¤å¾ªç¯æ’­æ”¾
          if (loopInterval) {{
            clearInterval(loopInterval);
            loopInterval = null;
            if (currentLoopingIndex) {{
              const el = document.getElementById('line-' + currentLoopingIndex);
              if (el) {{
                el.classList.remove('looping');
              }}
              currentLoopingIndex = null;
            }}
          }}
        }});
      }});
    </script>
    """

    st.components.v1.html(html, height=650, scrolling=False)

    # æ·»åŠ æ¨¡å—æ ‡é¢˜
    st.markdown(f'<h2 class="module-title">{current_lang["analysis_module"]}</h2>', unsafe_allow_html=True)
    st.markdown(f"#### {current_lang['full_text']}")
    
    # åˆå§‹åŒ– session state ç”¨äºå­˜å‚¨ç‚¹å‡»çš„å¥å­å’Œåˆ†æç»“æœ
    if 'clicked_sentence' not in st.session_state:
        st.session_state.clicked_sentence = None
    if 'last_analysis' not in st.session_state:
        st.session_state.last_analysis = None
    
    # æ˜¾ç¤ºæç¤ºä¿¡æ¯
    st.markdown(f"> <span style='color: #FFD700;'>{current_lang['hover_tip']}</span>", unsafe_allow_html=True)
    
    # åˆ›å»ºä¸€ä¸ªå®¹å™¨æ¥æ˜¾ç¤ºå…¨æ–‡
    full_text_container = st.container()
    
    # åœ¨å®¹å™¨ä¸­æ˜¾ç¤ºå…¨æ–‡
    with full_text_container:
        # ä½¿ç”¨è‡ªå®šä¹‰CSSæ¥ä¼˜åŒ–å¸ƒå±€
        st.markdown("""
        <style>
        .sentence-container {
            display: flex;
            margin-bottom: 15px;
            padding: 10px;
            border-radius: 5px;
            background-color: #f8f9fa;
        }
        .sentence-container:hover {
            background-color: #f0f0f0;
        }
        .japanese-text {
            flex: 3;
            padding-right: 20px;
            border-right: 1px solid #dee2e6;
        }
        .chinese-text {
            flex: 1;
            padding-left: 20px;
            color: #666;
        }
        .sentence-number {
            color: #666;
            font-size: 0.9em;
            margin-right: 8px;
            font-weight: bold;
        }
        </style>
        """, unsafe_allow_html=True)
        
        # ä¸ºæ¯ä¸ªå¥å­åˆ›å»ºä¸€ä¸ªå®¹å™¨
        for item in transcript_data:
            # åˆ›å»ºä¸¤åˆ—å¸ƒå±€
            cols = st.columns([3, 1])
            
            with cols[0]:
                # æ—¥æ–‡åŸæ–‡æŒ‰é’®
                if st.button(
                    f"[{item['index']}] {item['ja']}",
                    key=f"sentence_{item['index']}",
                    help=current_lang['click_to_analyze'],
                    use_container_width=True
                ):
                    sentence = item["ja"]
                    st.session_state.clicked_sentence = sentence
                    
                    # æ ¹æ®é€‰æ‹©çš„è¯­è¨€è®¾ç½®åˆ†ææç¤º
                    if selected_language == "ä¸­æ–‡":
                        analysis_prompt = f"""
                        è¯·ç”¨ä¸­æ–‡è¯¦ç»†åˆ†æä»¥ä¸‹æ—¥è¯­å¥å­ï¼Œå¿…é¡»åŒ…å«ä»¥ä¸‹æ‰€æœ‰å†…å®¹ï¼š

                        1. é‡ç‚¹è¯æ±‡åˆ†æï¼ˆè¯·ç”¨è¡¨æ ¼å½¢å¼å±•ç¤ºï¼‰ï¼š
                        | è¯æ±‡ | å‡åè¯»éŸ³ | è¯æ€§ | ä¸­æ–‡æ„æ€ | ä½¿ç”¨åœºæ™¯ |
                        |------|----------|------|----------|----------|
                        | è¯æ±‡1 | å‡å1 | è¯æ€§1 | æ„æ€1 | åœºæ™¯1 |
                        | è¯æ±‡2 | å‡å2 | è¯æ€§2 | æ„æ€2 | åœºæ™¯2 |
                        ...

                        2. è¯­æ³•ç‚¹åˆ†æï¼š
                           - è¯­æ³•ç»“æ„è¯´æ˜
                           - ç”¨æ³•è§£é‡Š
                           - 2-3ä¸ªç›¸å…³ä¾‹å¥
                        
                        3. å¥å­æ•´ä½“åˆ†æï¼š
                           - å¥å­ç±»å‹ï¼ˆé™ˆè¿°å¥ã€ç–‘é—®å¥ç­‰ï¼‰
                           - è¯­æ°”å’Œè¯­æ„Ÿ
                           - ä½¿ç”¨åœºæ™¯
                        
                        å¥å­ï¼š{sentence}
                        """
                        system_prompt = "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ—¥è¯­æ•™å¸ˆï¼Œæ“…é•¿ç”¨ä¸­æ–‡åˆ†ææ—¥è¯­è¯­æ³•å’Œè¯æ±‡ã€‚è¯·ç¡®ä¿åˆ†æå†…å®¹å…¨é¢ã€å‡†ç¡®ã€æ˜“æ‡‚ã€‚é‡ç‚¹è¯æ±‡åˆ†æå¿…é¡»ä½¿ç”¨è¡¨æ ¼å½¢å¼å±•ç¤ºã€‚"
                    elif selected_language == "English":
                        analysis_prompt = f"""
                        Please analyze the following Japanese sentence in detail, including ALL of the following:

                        1. Important Vocabulary Analysis (Please present in table format):
                        | Vocabulary | Furigana | Part of Speech | English Meaning | Usage Context |
                        |------------|----------|----------------|-----------------|---------------|
                        | Word 1 | Furigana 1 | POS 1 | Meaning 1 | Context 1 |
                        | Word 2 | Furigana 2 | POS 2 | Meaning 2 | Context 2 |
                        ...

                        2. Grammar Point Analysis:
                           - Grammar structure explanation
                           - Usage explanation
                           - 2-3 related example sentences
                        
                        3. Overall Sentence Analysis:
                           - Sentence type (declarative, interrogative, etc.)
                           - Tone and nuance
                           - Usage context
                        
                        Sentence: {sentence}
                        """
                        system_prompt = "You are a professional Japanese teacher, skilled in analyzing Japanese grammar and vocabulary in English. Please ensure the analysis is comprehensive, accurate, and easy to understand. Important vocabulary analysis must be presented in table format."
                    else:  # éŸ©æ–‡
                        analysis_prompt = f"""
                        ë‹¤ìŒ ì¼ë³¸ì–´ ë¬¸ì¥ì„ ìƒì„¸íˆ ë¶„ì„í•´ì£¼ì„¸ìš”. ë‹¤ìŒ ë‚´ìš©ì„ ëª¨ë‘ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤:

                        1. ì¤‘ìš” ì–´íœ˜ ë¶„ì„ (í‘œ í˜•ì‹ìœ¼ë¡œ ì œì‹œ):
                        | ì–´íœ˜ | í›„ë¦¬ê°€ë‚˜ | í’ˆì‚¬ | í•œêµ­ì–´ ì˜ë¯¸ | ì‚¬ìš© ë§¥ë½ |
                        |------|----------|------|------------|----------|
                        | ì–´íœ˜1 | í›„ë¦¬ê°€ë‚˜1 | í’ˆì‚¬1 | ì˜ë¯¸1 | ë§¥ë½1 |
                        | ì–´íœ˜2 | í›„ë¦¬ê°€ë‚˜2 | í’ˆì‚¬2 | ì˜ë¯¸2 | ë§¥ë½2 |
                        ...

                        2. ë¬¸ë²• í¬ì¸íŠ¸ ë¶„ì„:
                           - ë¬¸ë²• êµ¬ì¡° ì„¤ëª…
                           - ìš©ë²• ì„¤ëª…
                           - ê´€ë ¨ ì˜ˆë¬¸ 2-3ê°œ
                        
                        3. ì „ì²´ ë¬¸ì¥ ë¶„ì„:
                           - ë¬¸ì¥ ìœ í˜• (í‰ì„œë¬¸, ì˜ë¬¸ë¬¸ ë“±)
                           - ì–´ì¡°ì™€ ë‰˜ì•™ìŠ¤
                           - ì‚¬ìš© ë§¥ë½
                        
                        ë¬¸ì¥: {sentence}
                        """
                        system_prompt = "ë‹¹ì‹ ì€ ì¼ë³¸ì–´ ë¬¸ë²•ê³¼ ì–´íœ˜ë¥¼ í•œêµ­ì–´ë¡œ ë¶„ì„í•˜ëŠ” ì „ë¬¸ ì¼ë³¸ì–´ êµì‚¬ì…ë‹ˆë‹¤. ë¶„ì„ì´ í¬ê´„ì ì´ê³  ì •í™•í•˜ë©° ì´í•´í•˜ê¸° ì‰½ë„ë¡ í•´ì£¼ì„¸ìš”. ì¤‘ìš” ì–´íœ˜ ë¶„ì„ì€ ë°˜ë“œì‹œ í‘œ í˜•ì‹ìœ¼ë¡œ ì œì‹œí•´ì•¼ í•©ë‹ˆë‹¤."
                    
                    try:
                        analysis = openai.ChatCompletion.create(
                            model="gpt-4o-mini",
                            messages=[
                                {"role": "system", "content": system_prompt},
                                {"role": "user", "content": analysis_prompt}
                            ]
                        )
                        
                        # æ›´æ–°åˆ†æç»“æœ
                        st.session_state.last_analysis = analysis.choices[0].message.content
                        st.session_state.current_sentence = sentence
                    except Exception as e:
                        st.error(f"åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
            
            with cols[1]:
                # ä¸­æ–‡ç¿»è¯‘
                st.markdown(
                    f"<div style='padding-top: 8px;'><span class='sentence-number'>[{item['index']}]</span>{item['zh']}</div>", 
                    unsafe_allow_html=True
                )
    
    # æ˜¾ç¤ºåˆ†æç»“æœ
    if st.session_state.last_analysis:
        st.markdown("---")
        st.markdown(f"### {current_lang['sentence_analysis']}")
        st.markdown(f"**{current_lang['current_sentence']}** {st.session_state.current_sentence}")
        st.markdown(st.session_state.last_analysis)

st.snow()